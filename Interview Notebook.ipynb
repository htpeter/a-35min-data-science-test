{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "\n",
    "This notebook contains a set of programming questions that will test your ability to wrangle data in python. It will test your ability to injest, manipulate, and transform different types of data. While modeling and machine learning will not be a part of this test, a person who is familiar with data science will have worked with these methods as part of data cleaning, data analysis and validation.\n",
    "\n",
    "This is a timed 35 minute test. Just because you do not get through all the questions does not mean you are doing poorly. You are welcome to Google for the relevant APIs and documentation.\n",
    "\n",
    "**Try to group your ideas cleanly into functions where possible.** You should write code that is clean, simple, and to the point where possible. Do not be afraid to use fancy flairs occasionally to show us your style. \n",
    "\n",
    "Good Luck and Have Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:20:21.871632Z",
     "start_time": "2020-02-07T14:20:21.780967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "# This is to get you in the zone.\n",
    "import this\n",
    "\n",
    "# And these are some pieces used for when you need a hint (we all do some times!)\n",
    "from cryptography.fernet import Fernet\n",
    "key = b'qroFon14Mk22FqYltB9zv-IopBa2bs0LC45CWOOaOyE='\n",
    "f = Fernet(key)\n",
    "\n",
    "def decrypt_hint(encrypted_hint):\n",
    "    return f.decrypt(encrypted_hint)\n",
    "    \n",
    "def encrypt_hint(hint):\n",
    "    return f.encrypt(hint)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Theme: Beginner Data Manipulation\n",
    "\n",
    "Given a small data set, `./data/Q1-Resume-Metadata.csv`, about high level details regarding resumes, figure out how many documents belong to each `job_type`. \n",
    "\n",
    "Calculate the average length in words of each `document` in each `job_type`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 Answer Space\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Q1_FILE = './data/Q1-Resume-Metadata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Theme: Beginner NLP Preprocessing\n",
    "\n",
    "Using your datafile from Q1 `./data/Q1-Resume-Metadata.csv` in the current directory. Please load the data into a dataframe with each row being on the sentence level. \n",
    "\n",
    "Create the following columns. \n",
    "\n",
    "`document_id` - A unique identifier for that document. We didn't provide these so you can use any system as long as its unique across documents.\n",
    "\n",
    "`sentence_index` - An integer which determines the order of each sentence within the document. \n",
    "\n",
    "`sentence_text` - The actual text of the document.\n",
    "\n",
    "`sentence_tokens` - Tokenizee the sentence and store the results in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:09:52.544576Z",
     "start_time": "2020-02-07T14:09:52.415488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 2 Answer Space\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Q2_FILE = 'Q2-Job-Descriptions-Data.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need A Hint on Question 2? Try This Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypt_hint(b'gAAAAABehRX2LPOi70Bj9hRpT2Dtfa3KGjaYI8RQuU_ETM8nWKljfxVjwbQg3AkYZ3sSJ_tWxvhnr34g1XngcKrmkp-Oijfncb9w0P7KOah_NzlqPGOTLRys_qwODQtYrVOViVJ-t5qn2ng9iF2RNWE9hocM-DXodgtNPCcB-QItGMwZs8JfQwepEifY4VobsvDWX0ThcVIX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Theme: Classifier Validation\n",
    "\n",
    "You've built a classifier that scores a document's category. Your results are in `Q3-Sentence-Classifier-Results.csv`. Review your results and select a subset of the documents that you are fearful are not being classified strongly enough. Write a function that returns the IDs of these lower confidence documents so we can take some action with them.\n",
    "\n",
    "**The defintion of \"classified strongly enough\" is arbitrary and open to interpretation. Maybe your function also inputs a bit about the documents and why they were selected?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:25:40.324591Z",
     "start_time": "2020-02-07T14:25:39.841641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 3 Answer Space\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Q3_FILE = './data/Q3-Sentence-Classifier-Results.pickle'\n",
    "q3_df = pd.read_pickle(Q3_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypt_hint(b'gAAAAABehR-AiWE3JS4eoTSycCw-9odIdt6vUBPLzXZXpa3BPyBRB-FSLG-9bKo-FVRRFhxOOC654jKRqqwPLyCJqQNB22yTKU1mG9V1t6eGj-4CfZjeMUWIxjf3ulHvzJc4skMGtK5H5IAgs4VfFc9UCyxBdw4aIqROMbsVLDJMMwbSzg29VDnyy9XdxbVb4cUrHcJG51HxS4tGbr-H1u5e-Q6WNb8nK7D_O3iBDeFJsbBq0V7YCWgCFJ7omL5Z0FULLk0jP6SrMwU0nc-ODsGoVNiciXjKqg_5_qhc8IjXf3j4CLJuXyI=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 1 - Theme: Basic Probability & Visualization\n",
    "\n",
    "Generate 2 random arrays of numbers, 1 of them using a normal distribution and the other a uniform. Sort and plot a simple 2-D line chart. Familiar shape huh? Try to make the normal distribution exponential. Plot it again. Now reverse the exponential distribution and plot once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:19:09.703253Z",
     "start_time": "2020-02-07T14:19:09.700596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bonus Question 1 Answer Space\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need A Hint on Bonus Question 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:20:46.428073Z",
     "start_time": "2020-02-07T14:20:46.425921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stuck on generating distributions?\n",
    "decrypt_hint(b'gAAAAABePXItvyLA-Ou-Udm3lxZsxgLjFNkOMt2cFFvlhEGF2soYwpFYYdJlUiHPsDCrdtHzPmW47uWIbyYcn39M34A-cx45j3DqewKqCE3Sw-D8wzZNfjuXIbkwkYT_K3vnyyXCqgt1dQKvDL3bTI2quodzJJVYrpzgRvfsK6qQP-7ac-K7y7c=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:21:32.282178Z",
     "start_time": "2020-02-07T14:21:32.280001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stuck on getting a nice plot?\n",
    "decrypt_hint(b'gAAAAABePXJJ4IHj4CuN9Vv0e-rr9M41ozEtmwhaopjHTrN8QQMEENrq0Sf_0CZmCT5GZp7xG0UYLZ1bgcKBl42-Wu6D8pEKlAR1QFiq597Dn1VZx7QGE_WHVwl3clXiStTllVPsx6Bv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:22:40.743416Z",
     "start_time": "2020-02-07T14:22:40.741145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stuck on exponential and normal transformations?\n",
    "decrypt_hint(b'gAAAAABePXKlkxtT8LDZ3Y2XuoLiya-qBgI05i6TQAjTWkExyjYmgn0ir-vDv8zgQRrIWQmKbmpotOYlvtx0u2JD6CPTZ8qDTVX67qJlrkyKbUgynN6cpdq264B9fWCFDI1U7oUgnsY9104blxrfWOiarAVtWR3OF4w-9p8w3JbRxx1jurUXbO2JaW7K3LeS02RTYgQ0kU2T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question 2 - Theme: Intermediate NLP Preprocessing \n",
    "\n",
    "In Question 2 you generated a dataframe that had text and then tokenized each sentence. Using the `genism` snippet below and the docs, apply pre-trained embeddings to your sentences, resulting in an embedding space for each document. \n",
    "\n",
    "- [Genism Word2Vec Docs](https://radimrehurek.com/gensim/models/word2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T14:19:42.257889Z",
     "start_time": "2020-02-07T14:19:42.255769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bonus Question 2 Answer Space\n",
    "\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "GLOVE_PATH = './tools-for-interviewee/glove.6B.50d.txt.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need A Hint on Bonus Question 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T15:05:26.658335Z",
     "start_time": "2020-02-07T15:05:26.536169Z"
    }
   },
   "outputs": [],
   "source": [
    "decrypt_hint(b'gAAAAABehR_rPxhIjBukAygVOGRcdJCqesdudadYBTW2IiEDbSU-W64xXdzcQZexYqaHqasKSqafofjj4-iaBNAYJwAekZkkWwde0kSY7QKP6QQbDGy_YEcL0h2K1hSulQtxzbASzoUNaHhAV_r_S7yEokAYpwEmW2KRhcqubjQh54OgKaufxVkloHoiWWS7pG6lzB8SY7MAYvdJm0ilZlVAX2aoImAEHu2WIhCUVCtkaEEclOg-Rar1ZQepnq1fAdSB7mWIbIjc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
